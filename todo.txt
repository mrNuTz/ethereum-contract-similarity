DONE:
  CALLDATALOAD, CALLVALUE; CALLSIZE seams to be rare
  is swarm code removed from the skeletons? -> yes
  split framework and runs
  how can is split the framework and the test-runs and document the runs?
  extract abi jump table form contracts
  events? -> log
  define a few test sets
  select only code with distinct skeletons from es verified contracts and group by name + signatures
  verify that function are ordered by signatures in runtime code (deployed code) -> yes
  invalid byte-codes at the end of skeleton?
    Auxdata is the cryptographic fingerprint of the source code, used for verification.
    This is just data, and never executed by the EVM.
  add signature sim to many-solc-versions
  many-solc-versions
    why is there almost no signature overlap?
  ssdeep with spliced out 0s could perform pretty good, because functions are ordered
  add 2 more contract to many solc versions
  solc-versions optimization
  for each bytecode
    variance between groups / variance within groups
  save gml
  solc versions
    abi encoding
    more contracts
  separation measure
  test lzjd mode
  use normalized compression distance as reference
  refactor runs or just do it from know on
    compute all pairs
    distinguish groups later
    use lists not dicts
  are external functions always ordered by signature? -> yes
  compare lzjd parameters and compare to simple bz-compression-ration
  different lzjd parameters
  ppdeep variation -> jump hash
  more byte filters -> f-stat filter
  bzHash
  proxies
  check performance with different pre-processing methods
    whole code
    whole skeleton
    section one skeleton
  test wallets
  cluster wallet type
  bz use native Levenshtein
FIRST:
  name == main
  Cython language level
  numpy deprecated
  windows new lines
  sync repos
  readme
TODO:
  run force atlas and clustering () in python
  upload to gitLab
  go threw the runs one by one
    figure out what you want to figure out
    write what that is
    optional: redesign accordingly
    figure stuff out
    write whether you figured it out
    write what you figured out instead
  document none-obvious functions

  write readme

  check robustness against version, abi encoding and optimization changes separately
    clustering should show all that in one picture
LATER:
  skeletize rstrip trailing zeros?
  are internal functions ordered? how stable is the ordering?
QUESTIONS:
  what are data sections?
  why are there multiple meta sections?
  how will this be used?
MAYBE:
  write a hello world smart contract and compile it
  byteBags tuples instead of dicts
  ppdeep with custom chunk trigger
    def hashChunk(chunk) -> hash
    def digest(hash) -> digest
    def nextChunk(code, pos) -> pos
      min max chunk length
      ops
        JUMP
        JUMPI
        STOP = 0x00 # doesn't work with skeletons
        RETURN
        SELFDESTRUCT
        REVERT
        INVALID
    def hash(code) -> List[digest]
    def similarity(a: List[digest], b: List[digest]) -> float
