DONE:
  CALLDATALOAD, CALLVALUE; CALLSIZE seams to be rare
  is swarm code removed from the skeletons? -> yes
  split framework and runs
  how can is split the framework and the test-runs and document the runs?
  extract abi jump table form contracts
  events? -> log
  define a few test sets
  select only code with distinct skeletons from es verified contracts and group by name + signatures
  verify that function are ordered by signatures in runtime code (deployed code) -> yes
  invalid byte-codes at the end of skeleton?
    Auxdata is the cryptographic fingerprint of the source code, used for verification.
    This is just data, and never executed by the EVM.
  add signature sim to many-solc-versions
  many-solc-versions
    why is there almost no signature overlap?
  ssdeep with spliced out 0s could perform pretty good, because functions are ordered
  add 2 more contract to many solc versions
  solc-versions optimization
  for each bytecode
    variance between groups / variance within groups
  save gml
  solc versions
    abi encoding
    more contracts
  separation measure
  test lzjd mode
  use normalized compression distance as reference
  refactor runs or just do it from know on
    compute all pairs
    distinguish groups later
    use lists not dicts
  are external functions always ordered by signature? -> yes
FIRST:
  compare lzjd parameters and compare to simple bz-compression-ration
  go threw the runs one by one
    figure out what you want to figure out
    write what that is
    optional: redesign accordingly
    figure stuff out
    write whether you figured it out
    write what you figured out instead
TODO:
  check performance with different pre-processing methods
    whole code
    whole skeleton
    section one skeleton
  check robustness against version, abi encoding and optimization changes separately
    clustering should show all that in one picture
  document none-obvious functions
  similarity measures
    more byte filters
    different lzjd parameters
    ppdeep variations
      function splitting
    bzHash
LATER:
QUESTIONS:
  what are data sections?
  why are there multiple meta sections?
  how will this be used?
  how to split internal functions?
  deployment code vs deployed code?
  are internal functions ordered? how stable is the ordering?
  skeletize rstrip trailing zeros?
MAYBE:
  write a hello world smart contract and compile it
  byteBags should be tuples
  ppdeep with custom chunk trigger
    def hashChunk(chunk) -> hash
    def digest(hash) -> digest
    def nextChunk(code, pos) -> pos
      min max chunk length
      ops
        JUMP
        JUMPI
        STOP = 0x00 # doesn't work with skeletons
        RETURN
        SELFDESTRUCT
        REVERT
        INVALID
    def hash(code) -> List[digest]
    def similarity(a: List[digest], b: List[digest]) -> float
